/* generated by writeJava methods in Workspace */
package com.Tuuyi.TMPDataModel.generatedClasses.TMPDataModel;

import com.Tuuyi.TDM.*;
import org.apache.log4j.Logger;
import java.util.*;
import java.lang.reflect.Method;
import org.json.*;
import java.util.concurrent.ConcurrentHashMap;
import com.Tuuyi.TMPDataModel.generatedClasses.TMPDataModel.Namespace.DynamicCount;

public class Mapper extends DomainConcept {

  protected static final Logger logWriter = Logger.getLogger(Mapper.class.getName());
  private static final boolean persistant = false;

  public void inMemoryOnly(boolean local) {inMemoryOnly = local;}
  public boolean getInMemoryOnly() {return inMemoryOnly;}
  public boolean isPersistant() {return persistant;}

  public static boolean isPersistantClass() {return persistant;}

  protected GraphContext context = null;

  protected Namespace outputNamespace = null;

  protected GraphTMP hasModel = null;

  protected Namespace inputNamespace = null;

  protected Collector hasSink = null;

  protected Collector hasSource = null;


  /** if no arg, assume from db **/
  public Mapper() {
    this(true);
  }
  /** if from DB, set nonFunctional slot wrappers to stub **/
  /**    so subsequent slot get will do retrieval         **/
  public Mapper(boolean fromDB) {
    super(Workspace.getCurrentWorkspace(), fromDB);
  }
  public Mapper(Workspace workspace, boolean fromDB) {
    super(workspace, fromDB);
  }
  public boolean ContextIsResident() {
      return true;
  }
  public GraphContext getContext() {

    return context;
  }
  public int getContextInternalId() {
    if (context == null) {
      return -1;
    } else { 
      return context.getId();
    }
  }
  public boolean OutputNamespaceIsResident() {
      return true;
  }
  public Namespace getOutputNamespace() {

    return outputNamespace;
  }
  public int getOutputNamespaceInternalId() {
    if (outputNamespace == null) {
      return -1;
    } else { 
      return outputNamespace.getId();
    }
  }
  public int getId() {
    return id;
  }
  public boolean HasModelIsResident() {
      return true;
  }
  public GraphTMP getHasModel() {

    return hasModel;
  }
  public int getHasModelInternalId() {
    if (hasModel == null) {
      return -1;
    } else { 
      return hasModel.getId();
    }
  }
  public boolean InputNamespaceIsResident() {
      return true;
  }
  public Namespace getInputNamespace() {

    return inputNamespace;
  }
  public int getInputNamespaceInternalId() {
    if (inputNamespace == null) {
      return -1;
    } else { 
      return inputNamespace.getId();
    }
  }
  public boolean HasSinkIsResident() {
      return true;
  }
  public Collector getHasSink() {

    return hasSink;
  }
  public int getHasSinkInternalId() {
    if (hasSink == null) {
      return -1;
    } else { 
      return hasSink.getId();
    }
  }
  public boolean HasSourceIsResident() {
      return true;
  }
  public Collector getHasSource() {

    return hasSource;
  }
  public int getHasSourceInternalId() {
    if (hasSource == null) {
      return -1;
    } else { 
      return hasSource.getId();
    }
  }

  public void setContext(GraphContext newContext) {
    context = newContext;
  }

  public void setOutputNamespace(Namespace newOutputNamespace) {
    outputNamespace = newOutputNamespace;
  }
  public void setId (int a_id) {
      if (a_id> -1) {
        id = a_id;
      }
  }

  public void setHasModel(GraphTMP newHasModel) {
    hasModel = newHasModel;
  }

  public void setInputNamespace(Namespace newInputNamespace) {
    inputNamespace = newInputNamespace;
  }

  public void setHasSink(Collector newHasSink) {
    hasSink = newHasSink;
  }

  public void setHasSource(Collector newHasSource) {
    hasSource = newHasSource;
  }

  /* to support remove operation on collections, java objs are equal if id match */
  public boolean equals(Object o) {
    if (!(o instanceof Mapper)) //covers o == null case
      return false;
    Mapper other = (Mapper)o;
    if (this == other)
      return true;
    else
      return other.id == id;
  }

  /* to maintain hashCode contract */
  public int hashCode() {
    if (id == -1) {
      if (isPersistant()) {
        id = Workspace.makeGuid();
      } else {
        id = Workspace.nextId();
      }
    }
    return id;
  }

/** method to marshall data from caching layer object to JSON **/
  public JSONObject asJSON () {
    JSONObject jsonObj = new JSONObject();
    try {
      jsonObj.put("class", "Mapper");
      jsonObj.put("id", id);
      if (getContext() != null) {
        jsonObj.put("context", getContext().getId());
      }
      if (getOutputNamespace() != null) {
        jsonObj.put("outputNamespace", getOutputNamespace().getId());
      }
      jsonObj.put("id", getId());
      if (getHasModel() != null) {
        jsonObj.put("hasModel", getHasModel().getId());
      }
      if (getInputNamespace() != null) {
        jsonObj.put("inputNamespace", getInputNamespace().getId());
      }
      if (getHasSink() != null) {
        jsonObj.put("hasSink", getHasSink().getId());
      }
      if (getHasSource() != null) {
        jsonObj.put("hasSource", getHasSource().getId());
      }
    } catch (Exception e1) {
      logWriter.error("Error in marshalling to JSON ", e1);
    }
    return jsonObj;
  }


/** method to marshall data from caching layer object to JSON **/
  public JSONObject asJSONTree () {
    ConcurrentHashMap <DomainConcept, DomainConcept> written = new ConcurrentHashMap<DomainConcept, DomainConcept> ();
    return asJSONTreeAux(written);
  }
  public JSONObject asJSONTreeAux (ConcurrentHashMap<DomainConcept, DomainConcept> written) {
    JSONObject jsonObj = new JSONObject();
    try {
      jsonObj.put("class", "Mapper");
      jsonObj.put("id", id);
      if (written.contains(this)) {
        return jsonObj;
      }
      written.put(this, this);
      if (getContext() != null) {
        jsonObj.put("context", getContext().asJSONTreeAux(written));
      }
      if (getOutputNamespace() != null) {
        jsonObj.put("outputNamespace", getOutputNamespace().asJSONTreeAux(written));
      }
      jsonObj.put("id", getId());
      if (getHasModel() != null) {
        jsonObj.put("hasModel", getHasModel().asJSONTreeAux(written));
      }
      if (getInputNamespace() != null) {
        jsonObj.put("inputNamespace", getInputNamespace().asJSONTreeAux(written));
      }
      if (getHasSink() != null) {
        jsonObj.put("hasSink", getHasSink().asJSONTreeAux(written));
      }
      if (getHasSource() != null) {
        jsonObj.put("hasSource", getHasSource().asJSONTreeAux(written));
      }
      written.remove(this);
    } catch (Exception e1) {
      logWriter.error("Error in marshalling to JSON ", e1);
    }
    return jsonObj;
  }


/** method to update data in caching layer object from JSON **/
  public boolean updateFromJSON (JSONObject jsonObj) {
    try {
      if (!jsonObj.isNull("context")) {
        int contextId = jsonObj.optInt("context");
        GraphContext value = GraphContextManager.getInstance().get(contextId);
        if(value != null) {
            setContext(value);
        }
      }
      if (!jsonObj.isNull("outputNamespace")) {
        int outputNamespaceId = jsonObj.optInt("outputNamespace");
        Namespace value = NamespaceManager.getInstance().get(outputNamespaceId);
        if(value != null) {
            setOutputNamespace(value);
        }
      }
      if (!jsonObj.isNull("hasModel")) {
        int hasModelId = jsonObj.optInt("hasModel");
        GraphTMP value = GraphTMPManager.getInstance().get(hasModelId);
        if(value != null) {
            setHasModel(value);
        }
      }
      if (!jsonObj.isNull("inputNamespace")) {
        int inputNamespaceId = jsonObj.optInt("inputNamespace");
        Namespace value = NamespaceManager.getInstance().get(inputNamespaceId);
        if(value != null) {
            setInputNamespace(value);
        }
      }
      if (!jsonObj.isNull("hasSink")) {
        int hasSinkId = jsonObj.optInt("hasSink");
        Collector value = CollectorManager.getInstance().get(hasSinkId);
        if(value != null) {
            setHasSink(value);
        }
      }
      if (!jsonObj.isNull("hasSource")) {
        int hasSourceId = jsonObj.optInt("hasSource");
        Collector value = CollectorManager.getInstance().get(hasSourceId);
        if(value != null) {
            setHasSource(value);
        }
      }
    } catch (Exception e) {
      logWriter.error("Failure updating from JSON", e);
      return false;
    }
    return true;
  }


  protected HeapPriorityModel hpModel;
  //private HashMap<String, MapReduceItem> propagationIWorkspace = new HashMap<String, MapReduceItem> ();
  //private HashMap<String, MapReduceItem> propagationOWorkspace = new HashMap<String, MapReduceItem> ();
  public long propagationMark = 0;
  
  public static Mapper newMapper(GraphTMP model, Namespace inputNamespace, Collector source, Namespace outputNamespace, Collector sink) {
    Mapper mapper = new Mapper();
    mapper.setHasSource(source);
    mapper.setHasSink(sink);
    mapper.setHasModel(model);
    return mapper;
  }
  
  public MapReduceItem getAsOutput(String node) {
    MapReduceItem mri = hasSink.beliefspace.getMRI(node);
    if (mri == null) {
        logWriter.error("beliefspace returned null mri:"+node);
        mri = MapReduceItem.newMapReduceItem(node, 0.000000000001);
    }
    return mri;
  }

  public MapReduceItem [] getAsArrayInput(String node) {
    MapReduceItem mri = hasSource.beliefspace.getMRI(node);
    if (mri == null) {
      logWriter.error("beliefspace returned null mri:"+node);
      mri = MapReduceItem.newMapReduceItem(node, 0.000000000001);
    }
    MapReduceItem [] input = new MapReduceItem[1];
    input[0] = mri;
    return input;
  }

  public MapReduceItem getAsInput(String node) {
    MapReduceItem mri = hasSource.beliefspace.getMRI(node);
    if (mri == null) {
      DynamicCount count = ((InstanceSparseGraph)getHasModel()).inputNamespace.getMarginalCnt(node);
      double prior = .001;
      if (count != null) {
        prior = count.getMarginal();
      }
      mri = MapReduceItem.newMapReduceItem(node, prior);
      hasSource.beliefspace.setMRI(node, mri);
    }
    return mri;
  }

  public MapReduceItem [] getAsArrayInput(String [] nodes) {
    MapReduceItem [] input = new MapReduceItem[nodes.length];
    for (int i = 0; i < nodes.length; i++) {
      MapReduceItem mri = hasSource.beliefspace.getMRI(nodes[i]);
      if (mri != null) {
        input[i] = mri;
      }
    }
    return input;
  }

  public void clear() {
    for (MapReduceItem mri: hasSource.beliefspace.getKnownMRIs()) {
      DynamicCount count =inputNamespace.getMarginalCnt(mri.getItem());
      double prior = .001;
      if (count != null) {
        prior = count.getMarginal();
      }
      mri.setScore(prior);
      //mri.setMark(propagationWorkspaceMark);
    }
    for (MapReduceItem mri: hasSink.beliefspace.getKnownMRIs()) {
      DynamicCount count = outputNamespace.getMarginalCnt(mri.getItem());
      double prior = .001;
      if (count != null) {
        prior = count.getMarginal();
      }
      mri.setScore(prior);
      //mri.setMark(propagationWorkspaceMark);
    }
  }

  /**
   * scatters computation over a set of threads
   * should be generic, no need to override
   * 
   * Default is to scatter entire input. An alternative is to stream through based on collector pull.
   */

  public void scatter () { 
    scatter(true);
  }
  
  public void scatter (boolean fillin) {  // not used here, used in extension classes
    context.propagationMark++;
    while (getHasSource().hasMore()) {
      MapReduceInProcessItem item = getHasSource().nextItem();
      //logWriter.info("new scatter item:"+item.getHasMapReduceItem().getItem());
      map(item.getHasMapReduceItem(), item.getHasDelta(), item.getPropagationMark());
      item.hasMapReduceItem.getHasMapReduceIPIs().remove(item);
    }
  }
  
  public void scatter (boolean fillin, int targetCnt, long timeLimitMs) {  // not used here, used in extension classes
    context.propagationMark++;
    while (getHasSource().hasMore()) {
      MapReduceInProcessItem item = getHasSource().nextItem();
      //logWriter.info("new scatter item:"+item.getHasMapReduceItem().getItem());
      map(item.getHasMapReduceItem(), item.getHasDelta(), item.getPropagationMark());
      item.hasMapReduceItem.getHasMapReduceIPIs().remove(item);
    }
  }
  
  public void scatter (double collectThreshold) { 
    scatter (collectThreshold, true);
  }

  public void scatter (double collectThreshold, boolean fillin) { // not used here, used in extension classes
    context.propagationMark++;
    while (getHasSource().hasMore()) {
      MapReduceInProcessItem item = getHasSource().nextItem();
      MapReduceItem mri = item.getHasMapReduceItem();
      //logWriter.info("new scatter item:"+item.getHasMapReduceItem().getItem());
      map(item.getHasMapReduceItem(), item.getHasDelta(), item.getPropagationMark(), collectThreshold);
      mri.setScore(mri.getScore()+item.hasDelta);
      item.hasMapReduceItem.getHasMapReduceIPIs().remove(item);
    }
  }
  
  public void scatter (double collectThreshold, boolean fillin, int targetCnt, long timeLimitMs) { // not used here, used in extension classes
    context.propagationMark++;
    while (getHasSource().hasMore()) {
      MapReduceInProcessItem item = getHasSource().nextItem();
      MapReduceItem mri = item.getHasMapReduceItem();
      //logWriter.info("new scatter item:"+item.getHasMapReduceItem().getItem());
      map(item.getHasMapReduceItem(), item.getHasDelta(), item.getPropagationMark(), collectThreshold);
      mri.setScore(mri.getScore()+item.hasDelta);
      item.hasMapReduceItem.getHasMapReduceIPIs().remove(item);
    }
  }
  
  /**
   * maps a single { item, inputValue} pair through model
   * must be overridden by model-specific mappings
   */
  public void map (MapReduceItem item, double value, long propagationMark) {
    //logWriter.info("new map item:"+item.getItem());
    map (item, value, propagationMark, 0.0);
  }
  /**
   * maps a single { item, inputValue} pair through model
   * must be overridden by model-specific mappings
   */
  public void map (MapReduceItem item, double value, long propagationMark, double collectThreshold) {
    //logWriter.info("new map item:"+item.getItem());
  }
}
